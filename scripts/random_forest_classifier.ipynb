{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119e5a70",
   "metadata": {},
   "source": [
    "# Random Forest Classifier on Iris Dataset\n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78a1222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/arog/Documents/GitHub/si/')\n",
    "\n",
    "import numpy as np\n",
    "from si.io.csv_file import read_csv\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "from si.metrics.accuracy import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c6bdd",
   "metadata": {},
   "source": [
    "## Load Iris CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a1a06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_file = os.path.join('datasets/iris/iris.csv')\n",
    "iris_dataset = read_csv(filename=iris_file,features=True, label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2479e3d",
   "metadata": {},
   "source": [
    "## Display basic dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a47d64fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 4)\n",
      "Features: Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')\n",
      "Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset shape: {iris_dataset.X.shape}\")\n",
    "print(f\"Features: {iris_dataset.features}\")\n",
    "print(f\"Classes: {np.unique(iris_dataset.y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a9b8eb",
   "metadata": {},
   "source": [
    "## Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f1788ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 105\n",
      "Testing samples: 45\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = train_test_split(iris_dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {train_dataset.X.shape[0]}\")\n",
    "print(f\"Testing samples: {test_dataset.X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ba8d1",
   "metadata": {},
   "source": [
    "## Initialize and train the Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da72bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<si.models.random_forest_classifier.RandomForestClassifier at 0x70c323ee2fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=50,      # Number of trees\n",
    "    max_features=2,       # Number of features to consider at each split\n",
    "    min_sample_split=2,   # Minimum samples required to split a node\n",
    "    max_depth=5,          # Maximum depth of each tree\n",
    "    mode='gini',          # Split criterion\n",
    "    seed=42               # For reproducibility\n",
    ")\n",
    "\n",
    "rf.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e0933",
   "metadata": {},
   "source": [
    "## Make predictions on the test set and calculate and display accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002f0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(test_dataset)\n",
    "\n",
    "acc = accuracy(test_dataset.y, predictions)\n",
    "print(f\"Random Forest Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35de74c",
   "metadata": {},
   "source": [
    "## Compare with a single decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86ec6137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9556\n",
      "Random Forest Improvement: 0.0444\n"
     ]
    }
   ],
   "source": [
    "from si.models.decision_tree_classifier import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    min_sample_split=2,\n",
    "    max_depth=5,\n",
    "    mode='gini'\n",
    ")\n",
    "dt.fit(train_dataset)\n",
    "dt_predictions = dt.predict(test_dataset)\n",
    "dt_acc = accuracy(test_dataset.y, dt_predictions)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_acc:.4f}\")\n",
    "print(f\"Random Forest Improvement: {(acc - dt_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ba2e5",
   "metadata": {},
   "source": [
    "## Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cc00b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance:\n",
      "sepal_length: 0.520\n",
      "sepal_width: 0.380\n",
      "petal_length: 0.620\n",
      "petal_width: 0.480\n"
     ]
    }
   ],
   "source": [
    "feature_importance = np.zeros(iris_dataset.X.shape[1])\n",
    "for feature_idx, tree in rf.trees:\n",
    "    # This is a simplified approach - in a real implementation you'd track\n",
    "    # how often each feature is used for splits and their importance\n",
    "    for idx in feature_idx:\n",
    "        feature_importance[idx] += 1\n",
    "\n",
    "feature_importance /= len(rf.trees)  # Normalize\n",
    "\n",
    "print(\"\\nFeature importance:\")\n",
    "for name, importance in zip(iris_dataset.features, feature_importance):\n",
    "    print(f\"{name}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235ca29",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e5d4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "          Iris-setosa Iris-versicolor Iris-virginica\n",
      "Iris-setosa         19          0          0\n",
      "Iris-versicolor          0         13          0\n",
      "Iris-virginica          0          0         13\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def confusion_matrix(true_labels, pred_labels):\n",
    "    classes = np.unique(np.concatenate([true_labels, pred_labels]))\n",
    "    matrix = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        matrix[true][pred] += 1\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"          \" + \" \".join(f\"{cls:>10}\" for cls in classes))\n",
    "    for true in classes:\n",
    "        row = [matrix[true][pred] for pred in classes]\n",
    "        print(f\"{true:>10} \" + \" \".join(f\"{count:>10}\" for count in row))\n",
    "\n",
    "confusion_matrix(test_dataset.y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si_solo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
